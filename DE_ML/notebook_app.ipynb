{
 "metadata": {
  "kernelspec": {
   "display_name": "Streamlit Notebook",
   "name": "streamlit"
  }
 },
 "nbformat_minor": 5,
 "nbformat": 4,
 "cells": [
  {
   "cell_type": "code",
   "id": "8d50cbf4-0c8d-4950-86cb-114990437ac9",
   "metadata": {
    "language": "sql",
    "name": "cell2"
   },
   "source": "USE ROLE ACCOUNTADMIN;\n\nCREATE OR REPLACE WAREHOUSE DASH_S WAREHOUSE_SIZE=SMALL;\n\nUSE DASH_DB.DASH_SCHEMA;",
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "id": "c695373e-ac74-4b62-a1f1-08206cbd5c81",
   "metadata": {
    "language": "sql",
    "name": "cell3"
   },
   "source": "CREATE or REPLACE file format csvformat\n  skip_header = 1\n  type = 'CSV';\n\nCREATE or REPLACE stage campaign_data_stage\n  file_format = csvformat\n  url = 's3://sfquickstarts/ad-spend-roi-snowpark-python-scikit-learn-streamlit/campaign_spend/';\n\nCREATE or REPLACE TABLE CAMPAIGN_SPEND (\n  CAMPAIGN VARCHAR(60), \n  CHANNEL VARCHAR(60),\n  DATE DATE,\n  TOTAL_CLICKS NUMBER(38,0),\n  TOTAL_COST NUMBER(38,0),\n  ADS_SERVED NUMBER(38,0)\n);\n\nCOPY into CAMPAIGN_SPEND\n  from @campaign_data_stage;",
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "id": "b108f90e-75d0-4104-8801-5063b392d30b",
   "metadata": {
    "language": "sql",
    "name": "cell1"
   },
   "outputs": [],
   "source": "CREATE or REPLACE stage monthly_revenue_data_stage\n  file_format = csvformat\n  url = 's3://sfquickstarts/ad-spend-roi-snowpark-python-scikit-learn-streamlit/monthly_revenue/';\n\nCREATE or REPLACE TABLE MONTHLY_REVENUE (\n  YEAR NUMBER(38,0),\n  MONTH NUMBER(38,0),\n  REVENUE FLOAT\n);\n\nCOPY into MONTHLY_REVENUE\n  from @monthly_revenue_data_stage;",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "927a6857-47f5-4dae-b059-ca5123e5ffc2",
   "metadata": {
    "language": "sql",
    "name": "cell4"
   },
   "outputs": [],
   "source": "CREATE or REPLACE TABLE BUDGET_ALLOCATIONS_AND_ROI (\n  MONTH varchar(30),\n  SEARCHENGINE integer,\n  SOCIALMEDIA integer,\n  VIDEO integer,\n  EMAIL integer,\n  ROI float\n);\n\nINSERT INTO BUDGET_ALLOCATIONS_AND_ROI (MONTH, SEARCHENGINE, SOCIALMEDIA, VIDEO, EMAIL, ROI)\nVALUES\n('January',35,50,35,85,8.22),\n('February',75,50,35,85,13.90),\n('March',15,50,35,15,7.34),\n('April',25,80,40,90,13.23),\n('May',95,95,10,95,6.246),\n('June',35,50,35,85,8.22);",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "265f668b-4ed2-4789-a896-e302b68a5443",
   "metadata": {
    "language": "python",
    "name": "cell5"
   },
   "outputs": [],
   "source": "from snowflake.snowpark.session import Session\nfrom snowflake.snowpark.context import get_active_session\nfrom snowflake.snowpark.functions import month,year,col,sum\nfrom snowflake.snowpark.version import VERSION\nfrom snowflake.core import Root\nfrom snowflake.core.task import Task, StoredProcedureCall\nfrom snowflake.core.task.dagv1 import DAG, DAGTask, DAGOperation\nfrom snowflake.core import CreateMode\n\n# Misc\nfrom datetime import timedelta\nimport json\nimport logging \nlogger = logging.getLogger(\"snowflake.snowpark.session\")\nlogger.setLevel(logging.ERROR)\n\nsession = get_active_session()\n",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "e14bf29d-0316-448b-a98c-bc6de94a3500",
   "metadata": {
    "language": "python",
    "name": "cell6"
   },
   "outputs": [],
   "source": "\nsnow_df_spend = session.table('campaign_spend')\nsnow_df_spend.queries",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "e8f9247b-e2a5-4b59-bdd1-67185732670c",
   "metadata": {
    "language": "python",
    "name": "cell7"
   },
   "outputs": [],
   "source": "\nwith session.query_history() as history:\n    snow_df_spend.show(20)\nhistory.queries",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "08286870-a89f-4c33-bcad-ac916d83eaf7",
   "metadata": {
    "language": "python",
    "name": "cell8"
   },
   "outputs": [],
   "source": "# Stats per Month per Channel\nsnow_df_spend_per_channel = snow_df_spend.group_by(year('DATE'), month('DATE'),'CHANNEL').agg(sum('TOTAL_COST').as_('TOTAL_COST')).\\\n    with_column_renamed('\"YEAR(DATE)\"',\"YEAR\").with_column_renamed('\"MONTH(DATE)\"',\"MONTH\").sort('YEAR','MONTH')\n\nsnow_df_spend_per_channel.show(10)",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "fdcc7243-c233-4fae-a0f3-7957d55628b8",
   "metadata": {
    "language": "python",
    "name": "cell9"
   },
   "outputs": [],
   "source": "\nsnow_df_spend_per_month = snow_df_spend_per_channel.pivot('CHANNEL',['search_engine','social_media','video','email']).sum('TOTAL_COST').sort('YEAR','MONTH')\nsnow_df_spend_per_month = snow_df_spend_per_month.select(\n    col(\"YEAR\"),\n    col(\"MONTH\"),\n    col(\"'search_engine'\").as_(\"SEARCH_ENGINE\"),\n    col(\"'social_media'\").as_(\"SOCIAL_MEDIA\"),\n    col(\"'video'\").as_(\"VIDEO\"),\n    col(\"'email'\").as_(\"EMAIL\")\n)\nsnow_df_spend_per_month.show()\n     ",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "6c272a3b-307f-45b2-984b-35d1d2b463a8",
   "metadata": {
    "language": "python",
    "name": "cell10"
   },
   "outputs": [],
   "source": "\nsnow_df_spend_per_month.write.mode('overwrite').save_as_table('SPEND_PER_MONTH')",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "f0fd43e2-d099-4971-9b47-e9b87366a2ea",
   "metadata": {
    "language": "python",
    "name": "cell11"
   },
   "outputs": [],
   "source": "def campaign_spend_data_pipeline(session: Session) -> str:\n  # DATA TRANSFORMATIONS\n  # Perform the following actions to transform the data\n\n  # Load the campaign spend data\n  snow_df_spend_t = session.table('campaign_spend')\n\n  # Transform the data so we can see total cost per year/month per channel using group_by() and agg() Snowpark DataFrame functions\n  snow_df_spend_per_channel_t = snow_df_spend_t.group_by(year('DATE'), month('DATE'),'CHANNEL').agg(sum('TOTAL_COST').as_('TOTAL_COST')).\\\n      with_column_renamed('\"YEAR(DATE)\"',\"YEAR\").with_column_renamed('\"MONTH(DATE)\"',\"MONTH\").sort('YEAR','MONTH')\n\n  # Transform the data so that each row will represent total cost across all channels per year/month using pivot() and sum() Snowpark DataFrame functions\n  snow_df_spend_per_month_t = snow_df_spend_per_channel_t.pivot('CHANNEL',['search_engine','social_media','video','email']).sum('TOTAL_COST').sort('YEAR','MONTH')\n  snow_df_spend_per_month_t = snow_df_spend_per_month_t.select(\n      col(\"YEAR\"),\n      col(\"MONTH\"),\n      col(\"'search_engine'\").as_(\"SEARCH_ENGINE\"),\n      col(\"'social_media'\").as_(\"SOCIAL_MEDIA\"),\n      col(\"'video'\").as_(\"VIDEO\"),\n      col(\"'email'\").as_(\"EMAIL\")\n  )\n\n  # Save transformed data\n  snow_df_spend_per_month_t.write.mode('overwrite').save_as_table('SPEND_PER_MONTH')",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "43a6401c-6e76-49f6-b7a1-05b723f21110",
   "metadata": {
    "language": "python",
    "name": "cell12"
   },
   "outputs": [],
   "source": "\n# Register data pipeline function as a task\nroot = Root(session)\nmy_task = Task(name='campaign_spend_data_pipeline_task'\n               , definition=StoredProcedureCall(\n                   campaign_spend_data_pipeline, stage_location='@dash_sprocs'\n               )\n               , warehouse='DASH_S'\n               , schedule=timedelta(minutes=3))\n\ntasks = root.databases[session.get_current_database()].schemas[session.get_current_schema()].tasks\ntask_res = tasks.create(my_task,mode=CreateMode.or_replace)\n\n# By default a Task is suspended and we need to resume it if we want it run based on the schema. Note that we can still execute a task by calling the execute method.\ntask_res.execute()",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "628ab181-900b-46fb-a121-e26180159445",
   "metadata": {
    "language": "python",
    "name": "cell13"
   },
   "outputs": [],
   "source": "\nsnow_df_revenue = session.table('monthly_revenue')\nsnow_df_revenue_per_month = snow_df_revenue.group_by('YEAR','MONTH').agg(sum('REVENUE')).sort('YEAR','MONTH').with_column_renamed('SUM(REVENUE)','REVENUE')\nsnow_df_revenue_per_month.show()\n     ",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "f6239ced-12c6-4850-9853-33088a6a0663",
   "metadata": {
    "language": "python",
    "name": "cell14"
   },
   "outputs": [],
   "source": "snow_df_spend_and_revenue_per_month = snow_df_spend_per_month.join(snow_df_revenue_per_month, [\"YEAR\",\"MONTH\"])\nsnow_df_spend_and_revenue_per_month.show()\n     ",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "efce99e6-ccc1-44b8-a66a-233b66b11e41",
   "metadata": {
    "language": "python",
    "name": "cell15"
   },
   "outputs": [],
   "source": "\nsnow_df_spend_and_revenue_per_month.explain()",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "954e6307-3d79-4a3c-b9ba-0a83b07eed6e",
   "metadata": {
    "language": "python",
    "name": "cell16"
   },
   "outputs": [],
   "source": "\nsnow_df_spend_and_revenue_per_month.write.mode('overwrite').save_as_table('SPEND_AND_REVENUE_PER_MONTH')",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "e95b7b10-55ce-4cb9-8498-ca8a92bf6ec7",
   "metadata": {
    "language": "python",
    "name": "cell17"
   },
   "outputs": [],
   "source": "def monthly_revenue_data_pipeline(session: Session) -> str:\n  # Load revenue table and transform the data into revenue per year/month using group_by and agg() functions\n  snow_df_spend_per_month_t = session.table('spend_per_month')\n  snow_df_revenue_t = session.table('monthly_revenue')\n  snow_df_revenue_per_month_t = snow_df_revenue_t.group_by('YEAR','MONTH').agg(sum('REVENUE')).sort('YEAR','MONTH').with_column_renamed('SUM(REVENUE)','REVENUE')\n\n  # Join revenue data with the transformed campaign spend data so that our input features (i.e. cost per channel) and target variable (i.e. revenue) can be loaded into a single table for model training\n  snow_df_spend_and_revenue_per_month_t = snow_df_spend_per_month_t.join(snow_df_revenue_per_month_t, [\"YEAR\",\"MONTH\"])\n\n  # SAVE in a new table for the next task\n  snow_df_spend_and_revenue_per_month_t.write.mode('overwrite').save_as_table('SPEND_AND_REVENUE_PER_MONTH')\n     ",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "ce4d5835-9b74-44ec-9d8a-0d74072dedfb",
   "metadata": {
    "language": "python",
    "name": "cell18"
   },
   "outputs": [],
   "source": "# Delete the previous task\ntask_res.delete()\n\nwith DAG(\"de_pipeline_dag\", schedule=timedelta(minutes=3)) as dag:\n    # Create a task that runs our first pipleine\n    dag_spend_task = DAGTask(name='campaign_spend_data_pipeline_task'\n                        , definition=StoredProcedureCall(\n                                    campaign_spend_data_pipeline, stage_location='@dash_sprocs'\n                                )\n                        ,warehouse='DASH_S'\n                        )\n    # Create a task that runs our second pipleine\n    dag_revenue_task = DAGTask(name='monthly_revenue_data_pipeline'\n                          , definition=StoredProcedureCall(\n                                monthly_revenue_data_pipeline, stage_location='@dash_sprocs'\n                            )\n                        ,warehouse='DASH_S'\n                        )\n# Shift right and left operators can specify task relationships.\ndag_spend_task >> dag_revenue_task  # dag_spend_task is a predecessor of dag_revenue_task\n\nschema = root.databases[session.get_current_database()].schemas[session.get_current_schema()]\ndag_op = DAGOperation(schema)\n\ndag_op.deploy(dag,mode=CreateMode.or_replace)\n\n# A DAG is not suspended by default so we will suspend the root task that will suspend the full DAG\nroot_task = tasks[\"DE_PIPELINE_DAG\"]\nroot_task.suspend()",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "35fb56e7-dce9-41ec-ad09-532a67c08557",
   "metadata": {
    "language": "python",
    "name": "cell19"
   },
   "outputs": [],
   "source": "\n# dag_op.run(dag)",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "a14c481e-57d6-4d75-8086-c531dc5c00f1",
   "metadata": {
    "language": "python",
    "name": "cell20"
   },
   "outputs": [],
   "source": "\n# root_task = tasks[\"DE_PIPELINE_DAG\"]\n# root_task.resume()\n     ",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "b8b04669-106c-4695-acd7-a4c8af7e8c20",
   "metadata": {
    "language": "python",
    "name": "cell21"
   },
   "outputs": [],
   "source": "root_task = tasks[\"DE_PIPELINE_DAG\"]\nroot_task.suspend()",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "92016a8c-6bb4-4013-b61e-3ba19c12d95c",
   "metadata": {
    "language": "python",
    "name": "cell22"
   },
   "outputs": [],
   "source": "# Snowpark for Python\nfrom snowflake.snowpark.context import get_active_session\nfrom snowflake.snowpark.version import VERSION\n\n# Snowpark ML\nfrom snowflake.ml.modeling.compose import ColumnTransformer\nfrom snowflake.ml.modeling.pipeline import Pipeline\nfrom snowflake.ml.modeling.preprocessing import PolynomialFeatures, StandardScaler\nfrom snowflake.ml.modeling.linear_model import LinearRegression\nfrom snowflake.ml.modeling.model_selection import GridSearchCV\nfrom snowflake.ml.registry import Registry\nfrom snowflake.ml.version import VERSION as ml_version\n\n# Misc\n#import pandas as pd\nimport json\nimport logging \nlogger = logging.getLogger(\"snowflake.snowpark.session\")\nlogger.setLevel(logging.ERROR)\n\nsession = get_active_session()",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "94aca88e-997a-4f61-a740-b4936fa32390",
   "metadata": {
    "language": "python",
    "name": "cell23"
   },
   "outputs": [],
   "source": "\n# Load data\nsnow_df_spend_and_revenue_per_month = session.table('spend_and_revenue_per_month')\n\n# Delete rows with missing values\nsnow_df_spend_and_revenue_per_month = snow_df_spend_and_revenue_per_month.dropna()\n\n# Exclude columns we don't need for modeling\nsnow_df_spend_and_revenue_per_month = snow_df_spend_and_revenue_per_month.drop(['YEAR','MONTH'])\n\n# Save features into a Snowflake table call MARKETING_BUDGETS_FEATURES\nsnow_df_spend_and_revenue_per_month.write.mode('overwrite').save_as_table('MARKETING_BUDGETS_FEATURES')\nsnow_df_spend_and_revenue_per_month.show()",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "dd7490f8-d1b6-4d05-b366-1524e8e5e35a",
   "metadata": {
    "language": "python",
    "name": "cell24"
   },
   "outputs": [],
   "source": "CROSS_VALIDATION_FOLDS = 10\nPOLYNOMIAL_FEATURES_DEGREE = 2\n\n# Create train and test Snowpark DataDrames\ntrain_df, test_df = session.table(\"MARKETING_BUDGETS_FEATURES\").random_split(weights=[0.8, 0.2], seed=0)\n\n# Preprocess the Numeric columns\n# We apply PolynomialFeatures and StandardScaler preprocessing steps to the numeric columns\n# NOTE: High degrees can cause overfitting.\nnumeric_features = ['SEARCH_ENGINE','SOCIAL_MEDIA','VIDEO','EMAIL']\nnumeric_transformer = Pipeline(steps=[('poly',PolynomialFeatures(degree = POLYNOMIAL_FEATURES_DEGREE)),('scaler', StandardScaler())])\n\n# Combine the preprocessed step together using the Column Transformer module\npreprocessor = ColumnTransformer(\n    transformers=[\n        ('num', numeric_transformer, numeric_features)])\n\n# The next step is the integrate the features we just preprocessed with our Machine Learning algorithm to enable us to build a model\npipeline = Pipeline(steps=[('preprocessor', preprocessor),('classifier', LinearRegression())])\nparameteres = {}\n\n# Use GridSearch to find the best fitting model based on number_of_folds folds\nmodel = GridSearchCV(\n    estimator=pipeline,\n    param_grid=parameteres,\n    cv=CROSS_VALIDATION_FOLDS,\n    label_cols=[\"REVENUE\"],\n    output_cols=[\"PREDICTED_REVENUE\"],\n    verbose=2\n)\n\n# Fit and Score\nmodel.fit(train_df)\ntrain_r2_score = model.score(train_df)\ntest_r2_score = model.score(test_df)\n\n# R2 score on train and test datasets\nprint(f\"R2 score on Train : {train_r2_score}\")\nprint(f\"R2 score on Test  : {test_r2_score}\")\n     ",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "428fb4b4-37d5-41c8-b9d6-f5ce4d0fdd93",
   "metadata": {
    "language": "python",
    "name": "cell25"
   },
   "outputs": [],
   "source": "registry = Registry(session)\nMODEL_NAME = \"PREDICT_ROI\"",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "e250dcda-2039-4268-a5dd-01769e71534b",
   "metadata": {
    "language": "python",
    "name": "cell26"
   },
   "outputs": [],
   "source": "\n# NOTE: If you try to log the model with the same name, you may get \"ValueError: (0000) Model PREDICT_ROI version v1 already existed.\" error. \n# If that's the case, uncomment and run this cell.\n\n# registry.delete_model(MODEL_NAME)",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "b97772bf-3957-4410-9c65-1b6d0225ab97",
   "metadata": {
    "language": "python",
    "name": "cell27"
   },
   "outputs": [],
   "source": "\n\nmv = registry.log_model(model,\n                        model_name=MODEL_NAME,\n                        version_name=\"v1\",\n                        metrics={\"R2_train\": train_r2_score, \"R2_test\":test_r2_score},\n                        comment='Model pipeline to predict revenue',\n                        options={\"embed_local_ml_library\": True}\n                    )\n     ",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "877b984a-3a32-4737-aab5-35e026dfa53e",
   "metadata": {
    "language": "python",
    "name": "cell28"
   },
   "outputs": [],
   "source": "\nregistry.show_models()",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "70c0e1c9-5134-4cfd-9394-03ef3f8dbbe9",
   "metadata": {
    "language": "python",
    "name": "cell29"
   },
   "outputs": [],
   "source": "test_df = session.create_dataframe([[250000,250000,200000,450000],[500000,500000,500000,500000],[8500,9500,2000,500]], \n                                    schema=['SEARCH_ENGINE','SOCIAL_MEDIA','VIDEO','EMAIL'])\nmv.run(test_df, function_name='predict').show()",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "ac0ef294-e9e9-4b59-ae08-8c866ad35e37",
   "metadata": {
    "language": "python",
    "name": "cell30"
   },
   "outputs": [],
   "source": "# Snowpark for Python API reference: https://docs.snowflake.com/en/developer-guide/snowpark/reference/python/index.html\n# Snowpark for Python Developer Guide: https://docs.snowflake.com/en/developer-guide/snowpark/python/index.html\n\nimport calendar \nimport altair as alt\nimport streamlit as st\nimport pandas as pd\nimport snowflake.snowpark as snowpark \nfrom snowflake.snowpark.functions import col\n\n# Function to load last six months' budget allocations and ROI \ndef load():\n  data = session.table(\"BUDGET_ALLOCATIONS_AND_ROI\").unpivot(\"Budget\", \"Channel\", [\"SearchEngine\", \"SocialMedia\", \"Video\", \"Email\"]).filter(col(\"MONTH\") != \"July\")\n  alloc, rois, last_alloc = data.drop(\"ROI\"), data.drop([\"CHANNEL\", \"BUDGET\"]).distinct(), data.filter(col(\"MONTH\") == \"June\")\n  return data.to_pandas(), alloc.to_pandas(), rois.to_pandas(), last_alloc.to_pandas()\n\ndef predict(budgets):\n  pred = session.sql(f\"SELECT ABS(PREDICT_ROI!predict({budgets[0]*1000},{budgets[1]*1000},{budgets[2]*1000},{budgets[3]*1000})['PREDICTED_REVENUE']::int) as PREDICTED_ROI\").to_pandas()\n  pred = pred[\"PREDICTED_ROI\"].values[0] / 100000\n  change = round(((pred / rois[\"ROI\"].iloc[-1]) - 1) * 100, 1)\n  return pred, change\n\ndef chart(chart_data):\n  base = alt.Chart(chart_data).encode(alt.X(\"MONTH\", sort=list(calendar.month_name), title=None))\n  bars = base.mark_bar().encode(y=alt.Y(\"BUDGET\", title=\"Budget\", scale=alt.Scale(domain=[0, 300])), color=alt.Color(\"CHANNEL\", legend=alt.Legend(orient=\"top\", title=\" \")), opacity=alt.condition(alt.datum.MONTH==\"July\", alt.value(1), alt.value(0.3)))\n  lines = base.mark_line(size=3).encode(y=alt.Y(\"ROI\", title=\"Revenue\", scale=alt.Scale(domain=[0, 25])), color=alt.value(\"#808495\"))\n  points = base.mark_point(strokeWidth=3).encode(y=alt.Y(\"ROI\"), stroke=alt.value(\"#808495\"), fill=alt.value(\"white\"), size=alt.condition(alt.datum.MONTH==\"July\", alt.value(300), alt.value(70)))\n  chart = alt.layer(bars, lines + points).resolve_scale(y=\"independent\").configure_view(strokeWidth=0).configure_axisY(domain=False).configure_axis(labelColor=\"#808495\", tickColor=\"#e6eaf1\", gridColor=\"#e6eaf1\", domainColor=\"#e6eaf1\", titleFontWeight=600, titlePadding=10, labelPadding=5, labelFontSize=14).configure_range(category=[\"#FFE08E\", \"#03C0F2\", \"#FFAAAB\", \"#995EFF\"])\n  st.altair_chart(chart, use_container_width=True)\n\n# Streamlit config\nst.header(\"SkiGear Co Ad Spend Optimizer\")\nst.subheader(\"Advertising budgets\")\n\n# Call functions to get Snowflake session and load data\nsession = snowpark.session._get_active_session()\nchannels = [\"Search engine\", \"Email\", \"Social media\", \"Video\"]\nchannels_upper = [channel.replace(\" \", \"\").upper() for channel in channels]\ndata, alloc, rois, last_alloc = load()\nlast_alloc = last_alloc.replace(channels_upper, channels)\n\n# Display advertising budget sliders and set their default values\ncol1, _, col2 = st.columns([4, 1, 4])\nbudgets = []\nfor alloc, col in zip(last_alloc.itertuples(), [col1, col1, col2, col2]):\n  budgets.append(col.slider(alloc.CHANNEL, 0, 100, alloc.BUDGET, 5))\n\n# Function to call \"predict_roi\" UDF that uses the pre-trained model for inference\n# Note: Both the model training and UDF registration is done in Snowpark_For_Python.ipynb\npred, change = predict(budgets)\nst.metric(\"\", f\"Predicted revenue ${pred:.2f} million\", f\"{change:.1f} % vs last month\")\njuly = pd.DataFrame({\"MONTH\": [\"July\"]*4, \"CHANNEL\": channels_upper, \"BUDGET\": budgets, \"ROI\": [pred]*4})\nchart(pd.concat([data, july]).reset_index(drop=True).replace(channels_upper, channels))\n\n# Setup the ability to save user-entered allocations and predicted value back to Snowflake \nif st.button(\"❄️ Save to Snowflake\"):\n  with st.spinner(\"Making snowflakes...\"):\n    df = pd.DataFrame({\"MONTH\": [\"July\"], \"SEARCHENGINE\": [budgets[0]], \"SOCIALMEDIA\": [budgets[1]], \"VIDEO\": [budgets[2]], \"EMAIL\": [budgets[3]], \"ROI\": [pred]})\n    session.write_pandas(df, \"BUDGET_ALLOCATIONS_AND_ROI\")  \n    st.success(\"✅ Successfully wrote budgets & prediction to your Snowflake account!\")\n    st.snow()",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "7b673872-c6d2-44be-835e-4b891bd14bc8",
   "metadata": {
    "language": "python",
    "name": "cell31"
   },
   "outputs": [],
   "source": "root_task = tasks[\"DE_PIPELINE_DAG\"]\nroot_task.suspend()",
   "execution_count": null
  }
 ]
}